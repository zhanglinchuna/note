### 背景
在日常的列表查询中，通常会使用limit语句进行分页，当偏移量特别大时，sql的查询效率就会特别低下。

### 问题原因
当offset越大时无疑是增大**数据库扫描量**、**排序负担**成本

1. 数据扫描量增加：深分页意味着数据库需要从头开始扫描数据，直到达到所需的页码位置。页码越深，需要扫描和跳过的数据量就越大。例如，如果用户请求第100页的数据，每页显示10条记录，数据库就需要跳过前999条记录，才能获取到第1000到第1009条记录作为查询结果。这意味着数据库必须先处理这前999条记录，即使它们并不需要被返回。
3. 排序负担：分页查询往往伴随着排序操作，以确保数据的顺序性。数据库需要对整个结果集进行排序，然后才能确定每一页的数据。在深分页的情况下，排序操作需要处理的数据量巨大，这对数据库的资源消耗是非常显著的。
4. 索引利用率降低：虽然索引可以加速数据的查找速度，但在深分页的场景下，即使是索引扫描，数据库也需要遍历大量的索引项才能找到目标页的起始位置。这种大量的索引遍历操作降低了索引的效率。
5. 缓存命中率低：数据库和应用的缓存机制通常对常访问的数据有很好的优化效果。但在深分页场景下，由于用户可能访问任意页的数据，这些数据的访问模式具有很高的随机性，导致缓存命中率低，每次查询都可能需要直接访问磁盘数据。
6. 内存和网络开销：为了找到目标页的数据，数据库需要将大量数据加载到内存中进行处理，然后再丢弃大部分数据，只返回少量的结果。这个过程中，不仅消耗了大量的内存资源，还可能增加了网络传输的负担（在分布式数据库环境中尤为明显）。

举个分页查询订单列表的例子：

```sql
-- 跳过前100页，取100页之后的10条数据
select * from order where order_status = 1 limit 100, 10;
```
这条分页sql含义：用户请求第100页的数据，每页显示10条记录，数据库就需要跳过前999条记录，获取到第1000到第1009条记录作为查询结果。

> 之所以不能直接跳过前999条记录而直接取第1000到第1009条记录，原因主要在于数据库的数据存储和索引机制。有以下几个方面的原因：
> 
> 1. 数据存储结构：数据库中的数据通常以行的形式存储在表中，这些行并不是按照查询条件预先排序的。因此，为了找到第1000到第1009条符合条件的记录，数据库必须从头开始按顺序扫描数据，以确保正确地跳过前999条记录。
> 2. 索引机制：虽然索引可以加速特定条件下的数据查找，但索引本身并不存储数据行的全部信息，而是存储了指向数据行的指针。如果查询条件涉及到非索引列或者需要返回的数据不完全包含在索引中（即非覆盖索引查询），数据库仍然需要回到数据表中检索完整的行数据。此外，即使使用索引，数据库也需要遍历索引来确定符合条件的记录的具体位置。
> 3. 排序和条件过滤：分页查询往往伴随着排序和条件过滤。数据库需要先对整个结果集进行排序和过滤，以确保返回的数据是正确和期望的。这个过程中，数据库必须处理每一条记录，以确定它们是否满足查询条件和排序要求。

查询慢的问题本质：**将所有满足条件的记录先筛选出来然后排序，再取指定位置的指定条数记录**

### 解决方案

1. 使用游标分页：游标分页不是基于OFFSET的分页方式，而是记住上一次查询返回的最后一条记录的位置，下一次查询从这个位置开始。这种方式适用于数据变动不频繁的场景。
2. ID范围查询：在查询时，不使用OFFSET和LIMIT，而是记录上一次查询的最大ID，下一次查询时，添加条件WHERE id > 上次查询的最大ID，这样可以避免跳过大量记录。
